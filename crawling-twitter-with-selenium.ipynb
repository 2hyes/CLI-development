{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('securityml': conda)",
   "display_name": "Python 3.8.5 64-bit ('securityml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bedcc662f9a039a32db907ceb9f5c533a6e6233c8656c177c8c508a47fdfb6cf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "source": [
    "## twitter automatic login\n",
    "참고: https://jhnoru.tistory.com/59"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "driver 가동\n",
    ": web browser는 chrome 사용\n",
    "\"\"\"\n",
    "def init_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.wait = WebDriverWait(driver, 5)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "\n",
    "def close_driver(driver):\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "크롬을 조작해서 트위터에 로그인\n",
    ": 개인 id 및 pw이용\n",
    "\"\"\"\n",
    "def twitter_login(driver, username, password):\n",
    "    driver.get(\"https://twitter.com/login\")\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    username_field = driver.find_element_by_name(\"session[username_or_email]\")\n",
    "    password_field = driver.find_element_by_name(\"session[password]\")\n",
    "\n",
    "    username_field.send_keys(username)\n",
    "    driver.implicitly_wait(1)\n",
    "    password_field.send_keys(password)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "    driver.find_element_by_xpath('//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div[1]/form/div/div[3]/div/div/span/span').submit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(driver):\n",
    "    data = []\n",
    "    TWITTER_URL = \"https://twitter.com/search?q=%EA%B2%BD%EC%A0%9C%20until%3A2020-09-29%20since%3A2020-09-28%20-filter%3Alinks&src=typed_query\"\n",
    "\n",
    "    driver.maximize_window()\n",
    "    driver.get(TWITTER_URL)\n",
    "\n",
    "    print('The scroll is starting to move bottom')\n",
    "\n",
    "    # 페이지 스크롤을 끝날 때까지 계속 내림\n",
    "    # 스크롤을 내리기 전의 화면 높이와 내렸을 때의 화면 높이가 같다면 더 이상 내려갈 곳이 없다는 의미이므로 무한 루프를 탈출함.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        time.sleep(1)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            # Wait to load page\n",
    "            time.sleep(1)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            if(new_height == last_height):\n",
    "                break\n",
    "\n",
    "        last_height = new_height\n",
    "    print('Arrived at the end of the page')\n",
    "    print('Start twitter crawling')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # 트위터의 게시글에는 각각의 고유의 아이디가 있어서 트위터 사이트에서 모든 게시글 아이디를 리스트형으로 가져옴\n",
    "    pattern = re.compile('stream-item-tweet-\\d+')\n",
    "    items = pattern.findall(str(soup))\n",
    "    for item in items:\n",
    "        # 위에서 가져온 고유 아이디를 이용하여 게시글 본문을 css selector를 이용하여 가져\n",
    "        text = driver.find_element_by_css_selector('#'+ item +' > div > div.content > div.js-tweet-text-container > p').text\n",
    "\n",
    "        # 특수기호를 없애는 작업\n",
    "        for idx in range(len(text)):\n",
    "            if not ((0 <= ord(text[idx]) < 128) or (0xac00 <= ord(text[idx]) <= 0xd7af)):\n",
    "                text = text.replace(text[idx], ' ')\n",
    "\n",
    "        data.append(text)\n",
    "\n",
    "    \n",
    "    print('Finish crawling')\n",
    "    print('The data is being written to the csv file.')\n",
    "    dataframe = pd.DataFrame(data, columns=[\"content\"])\n",
    "    dataframe.to_csv('twitter_comment.csv', mode = 'a', encoding='cp949')\n",
    "    print('Finish working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The scroll is starting to move bottom\nArrived at the end of the page\nStart twitter crawling\nFinish crawling\nThe data is being written to the csv file.\nFinish working\n"
    },
    {
     "output_type": "error",
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-25-fc4ac9b4a3fd&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcrawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----&gt; 7\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\securityml\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         &quot;&quot;&quot;\n\u001b[1;32m--&gt; 688\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\securityml\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response[&#39;value&#39;] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get(&#39;value&#39;, None))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\securityml\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m&#39;alert&#39;\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&#39;text&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m: Message: invalid session id\n"
     ]
    }
   ],
   "source": [
    "#driver = webdriver.Chrome('C:/chromedriver_win32/chromedriver')\n",
    "driver = init_driver()\n",
    "twitter_login(driver, 'twitter_user_id', 'twitter_user_pw')\n",
    "\n",
    "crawling(driver)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "자동 로그인까지 성공.\\\n",
    "검색어 query로 크롤링 시도하고자함."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 혜승 크롤링 연습"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(driver, start_year, start_month, start_day, until_year, until_month, until_day):\n",
    "    startdate = dt.date(year = start_year,month = start_month, day = start_day)\n",
    "    untildate = dt.date(year = until_year,month = until_month, day = until_day)\n",
    "\n",
    "    #TWITTER_URL = \"https://twitter.com/search?q=%EA%B2%BD%EC%A0%9C%20until%3A2020-09-30%20since%3A2020-09-29%20-filter%3Alinks&src=typed_query\"\n",
    "    \n",
    "    TWITTER_URL = \"https://twitter.com/search?q=%EA%B2%BD%EC%A0%9C%20until%3A\" + str(untildate) + \"%20since%3A\"+ str(startdate) +\"%20-filter%3Alinks&src=typed_query\"\n",
    "\n",
    "    driver.maximize_window()\n",
    "    driver.get(TWITTER_URL)\n",
    "\n",
    "    print('The scroll is starting to move bottom')\n",
    "\n",
    "    # 페이지 스크롤을 끝날 때까지 계속 내림\n",
    "    # 스크롤을 내리기 전의 화면 높이와 내렸을 때의 화면 높이가 같다면 더 이상 내려갈 곳이 없다는 의미이므로 무한 루프를 탈출함.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        time.sleep(1)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            # Wait to load page\n",
    "            time.sleep(1)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            if(new_height == last_height):\n",
    "                break\n",
    "\n",
    "        last_height = new_height\n",
    "    print('Arrived at the end of the page')\n",
    "    print('Start twitter crawling')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # 날짜 저장된 태그: day\n",
    "    day = soup.find_all(\"a\", {\"class\": \"r-1re7ezh r-1loqt21 r-1q142lx r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-3s2u2q r-qvutc0 css-4rbku5 css-18t94o4 css-901oao\"})\n",
    "    tweets = soup.find_all(\"div\", {\"class\": \"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\"})\n",
    "    return day, tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The scroll is starting to move bottom\nArrived at the end of the page\nStart twitter crawling\n"
    }
   ],
   "source": [
    "driver = init_driver()\n",
    "twitter_login(driver, 'twitter_user_id', 'twitter_user_pw')\n",
    "\n",
    "day, tweets = crawling(driver, 2020, 9, 29, 2020, 9, 30)\n",
    "driver.quit()"
   ]
  },
  {
   "source": [
    "전체 글이 긁어와지지않음. 더 분석해봐야할듯! + 키워드 조정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n9월 30일\n"
    }
   ],
   "source": [
    "# 날짜 저장된 태그\n",
    "for a in day:\n",
    "    print(a.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "승뉸이 슈스케 끝나고 경제적으로 힘든 상태였는데 광고 찍은거랑 행사 뛴거 미리 정산해줘서 빚 갚았대.. 회사에 돈이 많으니 그런 쪽으로는 클린한 듯..\n\n\n[효민] 향수는 달콤한 향이나 바닐라 향을 좋아한다. (한국경제-스타들의 수다)\n\n\n카와세가 산리오를 좋아하는 것도... 어찌보면 당시의 상황적 맥락이 좀 작용하죠 일본 경제가 잃어버린 10년(요즘은 20년이라 합니다)을 겪는 동안 산리오의 매출도 위터러웠어요 캐릭터 상품이 고가에 팔리던 시절인데, 이때부터 한정된 캐릭터가 아닌 보다 다양한 캐릭터를, 여러 가격대에 맞춰\n\n\n뭐 중요한 건 카와세네 아버지 집안과 어머니 집안은 사이가 좋지 않습니다.... 아버지 쪽은 거품 경제 당시 나름 건실했던 토목공사 사업들의 수익을 부동산에 투자했다 이후 망한 뒤 미국에서 돌아오는 집안인데, 집안 자체가 화려했던 그 시절을 잊지 못하고 씀씀이도 큰 편입니다...\n\n\n추석경제\n2차재난지원금 효과\n안보임\n\n돈을써도 쓰는효과\n없도록 쓰느라 애썼다\n\n\n경제와 방역 사이 헤매다.. 300조원 붓고도 경제불확실성 사상 최대\n내년에도 코로나바이러스는 지속된다\n코로나바이러스는 문재인과 같이 종식될지도 모른다\n\n\n가능성 정도야 있다고 생각해. 근데 생각한다고 뭔가 바뀌는 건 아니지? 당장 나갈수도 없지? 안에 있다고 상황이 더 좋은것도 아니지? 그렇다면 믿지 않는 쪽이 경제적이라고 생각했는데~\n\n\n다아는목적\n\n바보작가소산\n\n생존목숨을\n위하여\n돈경제를위하여\n행복재미를\n위하여\n우리는\n지금 여기에서\n무엇을\n위해\n움직이는가?\n\n\n경제적으로 독립하고싶다\n\n\n세계의 정치와 경제를 암암리에 조종하는 패라디우스 사(社) 역시 도마의 힘에 의해 고대부터 축적된 부를 바탕으로 만들어진 기업이다\n\n\n제 5 공화국 다시 보는데.. 전두환이라는 인간. 박정희라는 인간이 없었어도.. 경제 발전도 그대로였을테고..독재정권도 누가 또 만들었겠지. 다만 박정희는 몰라도 전두환은 그때 민주주의가 시작될 수 있었는데.. 그 다음 분기점은 3당 합당...\n\n\n"
    }
   ],
   "source": [
    "for a in tweets:\n",
    "    print(a.get_text())\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}